{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9V5ptJAIEbw"
   },
   "source": [
    "# FIT5197 2024 S1 Assignment - Covers the lecture and tutorial materials up to, and including, week 8\n",
    "\n",
    "**SPECIAL NOTE:** Please refer to the [assessment page]() for rules, general guidelines and marking rubrics of the assessment (the marking rubric for the kaggle competition part will be released near the deadline in the same page). Failure to comply with the provided information will result in a deduction of mark (e.g., late penalties) or breach of academic integrity.\n",
    "\n",
    "**No external R libraries allowed. Only base packages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Point Estimation (30 marks)\n",
    "**WARNING:** you should strictly follow the 3-steps strategy as detailed in [question 2 of week 5 tutorial]() \\(or any answer formats presented in the [Week 5 quiz]()\\) to answer for the questions that are related to MLE estimators presented in this part. Any deviations from the answer format might result in a loss of marks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (7.5 marks)\n",
    "\n",
    "Let $X\\,{\\sim}\\,\\mathcal{IG}\\left(\\theta: \\left(\\mu, \\lambda\\right)\\right),\\;\\,\\forall\\, \\mu>0 \\text{ and } \\lambda>0$. This means\n",
    "the random varible $X$ follows the **inverse Gaussian distribution** with the set $\\left(\\theta: \\left(\\mu, \\lambda\\right)\\right)$ acting as the parameters of said distribution. Given that we observe a sample of size $n$ that is independently and identically distributed from this distribution ([i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)), $\\mathbf{x}=$ $\\left(x_{1}, \\ldots, x_{n}\\right)$, please find the [maximum likelihood estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) for $\\mu$ and $\\lambda$, that is $\\mu_{\\text{MLE}}$ and $\\lambda_{\\text{MLE}}$. The probability density function (**PDF**) is as follows:\n",
    "\n",
    "$$\n",
    "f(x \\mid \\mu, \\lambda)=\\left\\{\\begin{array}{cc}\n",
    "\\left(\\frac{\\lambda}{2 \\pi x^{3}}\\right)^{1 / 2} e^{\\frac{-\\lambda(x-\\mu)^{2}}{2 \\mu^{2} x}}, & x>0 \\\\\n",
    "0, & x \\leq 0\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "Given: \n",
    "$X\\,{\\sim}\\,\\mathcal{IG}\\left(\\theta: \\left(\\mu, \\lambda\\right)\\right)$ follows a inverse gaussian distribution.   \n",
    "The pdf is given by: $$\n",
    "f(x \\mid \\mu, \\lambda)=\\left\\{\\begin{array}{cc}\n",
    "\\left(\\frac{\\lambda}{2 \\pi x^{3}}\\right)^{1 / 2} e^{\\frac{-\\lambda(x-\\mu)^{2}}{2 \\mu^{2} x}}, & x>0 \\\\\n",
    "0, & x \\leq 0\n",
    "\\end{array}\\right.\n",
    "$$ \n",
    "We need to find maximum likelihood estimators for $\\mu$ and $\\lambda$. \n",
    "\n",
    "Step 1: Finding likelihood function for $f(x \\mid \\mu, \\lambda)$:  \n",
    "We know that likelihood function is given by: \n",
    "$$L(x|\\mu,\\lambda) = \\prod_{i=1}^{n} {f(x|\\mu,\\lambda)}$$  \n",
    "Writing Likelihood with respect to PDF,\n",
    "$$ L(x|\\mu,\\lambda) = \\prod_{i=1}^{n} {(\\frac{\\lambda}{2\\pi x^3})}^{(\\frac{1}{2})}e^{\\frac{-\\lambda(x-\\mu)^2}{2\\mu^2x}} $$\n",
    "\n",
    "Step 2: Taking Negative Log-likelihood function for the above likelihood equation: \n",
    "$$ L(x|\\mu,\\lambda) = - \\log \\left( \\prod_{i=1}^n \\left(\\frac{\\lambda}{2\\pi x_i^3}\\right)^{1/2} \\exp\\left(-\\frac{\\lambda(x_i - \\mu)^2}{2\\mu^2 x_i}\\right) \\right)$$  \n",
    "Considering property of logarithms, $\\log(a \\cdot b) = \\log(a) + \\log(b) $ we can simply as follows: \n",
    "$$ = - \\sum_{i=1}^n \\left( \\frac{1}{2} \\log\\left(\\frac{\\lambda}{2\\pi x_i^3}\\right) - \\log\\left( e^{\\frac{-\\lambda(x-\\mu)^2}{2\\mu^2x}}\\right)\\right)$$\n",
    "$$= - \\sum_{i=1}^n \\left( \\frac{1}{2} \\log\\left(\\frac{\\lambda}{2\\pi x_i^3}\\right) - \\frac{\\lambda (x_i - \\mu)^2}{2\\mu^2 x_i} \\right)$$\n",
    "$$= - \\sum_{i=1}^n \\left( \\frac{1}{2} \\log(\\lambda) - \\frac{1}{2} \\log(2\\pi) - \\frac{3}{2} \\log(x_i) - \\frac{\\lambda (x_i - \\mu)^2}{2\\mu^2 x_i} \\right)$$ \n",
    "$$-L(x|\\mu,\\lambda) = -\\frac{n}{2} \\log(\\lambda) + \\frac{n}{2} \\log(2\\pi) + \\frac{3}{2} \\sum_{i=1}^n \\log(x_i) + \\sum_{i=1}^n \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i}-------(D)$$ \n",
    "\n",
    "Now in order to find the maximum estimators for $\\mu$ and $\\lambda$ we partially derrive with respect to it by substituitng the above equation to zero. \n",
    "\n",
    "Step 3: First we partially derrive with respect to $\\mu$, Considering equation D, since we are partially deriving with respect to $\\mu$ other elements in the equation which do consists $\\mu$ will be zero while partially deriving and below is the resultant.  \n",
    "$$\\frac{\\partial}{\\partial \\mu} -L(x|\\mu,\\lambda) = \\frac{\\partial}{\\partial \\mu} \\left( \\sum_{i=1}^n \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i} \\right)$$ \n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\mu} \\left(-L(x|\\mu,\\lambda)\\right) = \\frac{\\partial}{\\partial \\mu} \\left( \\sum_{i=1}^n \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i} \\right) $$ \n",
    "\n",
    "Applying Chain Rule, We get: \n",
    "$$\\frac{\\partial}{\\partial \\mu} \\left( \\frac{(x_i - \\mu)^2}{\\mu^2} \\right) = \\frac{\\partial}{\\partial \\mu} \\left( \\frac{x_i^2 - 2 \\mu x_i + \\mu^2}{\\mu^2} \\right)$$\n",
    "\n",
    "$$= \\frac{\\partial}{\\partial \\mu} \\left( \\frac{x_i^2}{\\mu^2} - \\frac{2 x_i}{\\mu} + 1 \\right)$$\n",
    "$$ = \\frac{-2 x_i^2}{\\mu^3} + \\frac{2 x_i}{\\mu^2} $$\n",
    "$$\\frac{\\partial}{\\partial \\mu} \\left( \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i} \\right) = \\frac{\\lambda}{2 x_i} \\left( \\frac{-2 x_i^2 + 2 \\mu x_i}{\\mu^3} \\right)$$\n",
    "$$ = \\frac{\\lambda}{2 x_i} \\left( \\frac{2 x_i (\\mu - x_i)}{\\mu^3} \\right) $$\n",
    "\n",
    "$$= \\frac{\\lambda (\\mu - x_i)}{\\mu^3}$$ \n",
    "\n",
    "Now considering for all values of n we get as follows: \n",
    "$$\\frac{\\partial}{\\partial \\mu} \\left(-L(x|\\mu,\\lambda)\\right) = \\sum_{i=1}^n \\frac{\\lambda (\\mu - x_i)}{\\mu^3} = 0 $$\n",
    "\n",
    "Simplifying:\n",
    "$$ \n",
    "\\frac{\\lambda}{\\mu^3} \\sum_{i=1}^n (\\mu - x_i) = 0 \n",
    "$$\n",
    "$$ \n",
    "\\sum_{i=1}^n (\\mu - x_i) = 0 \n",
    "$$\n",
    "$$ \n",
    "n \\mu - \\sum_{i=1}^n x_i = 0 \n",
    "$$   \n",
    "Therefore Maximum likelihood estimator for $\\mu$ is sample mean. \n",
    "$$\n",
    "\\mu_{\\text{MLE}} = \\frac{\\sum_{i=1}^n x_i}{n} $$  \n",
    "\n",
    "Step 4: Now we find maximum likelihood estimator for $\\lambda$ by partially deriving with respect to it. \n",
    "$$ \n",
    "\\frac{\\partial}{\\partial \\lambda} \\left( -L(x|\\mu,\\lambda) \\right) = \\frac{\\partial}{\\partial \\lambda} \\left( -\\frac{n}{2} \\ln(\\lambda) + \\sum_{i=1}^n \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i} \\right) \n",
    "$$\n",
    "\n",
    "Let's compute the derivative step by step:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\lambda} \\left( -\\frac{n}{2} \\ln(\\lambda) \\right) = -\\frac{n}{2 \\lambda} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\lambda} \\left( \\sum_{i=1}^n \\frac{\\lambda (x_i - \\mu)^2}{2 \\mu^2 x_i} \\right) = \\sum_{i=1}^n \\frac{(x_i - \\mu)^2}{2 \\mu^2 x_i} \n",
    "$$\n",
    "\n",
    "Summing these results:\n",
    "$$\n",
    "-\\frac{n}{2 \\lambda} + \\sum_{i=1}^n \\frac{(x_i - \\mu_{\\text{MLE}})^2}{2 \\mu_{\\text{MLE}}^2 x_i} = 0 \n",
    "$$\n",
    "\n",
    "Solving for $\\lambda$:\n",
    "$$\n",
    "\\frac{n}{2 \\lambda} = \\sum_{i=1}^n \\frac{(x_i - \\mu_{\\text{MLE}})^2}{2 \\mu_{\\text{MLE}}^2 x_i} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_{\\text{MLE}} = \\frac{n}{\\sum_{i=1}^n \\frac{(x_i - \\mu_{\\text{MLE}})^2}{\\mu_{\\text{MLE}}^2 x_i}} \n",
    "$$ \n",
    "\n",
    "#### Therefore the MLE estimators are \n",
    "$$\\mu_{\\text{MLE}} = \\frac{\\sum_{i=1}^n x_i}{n} $$  and\n",
    "\n",
    "$$\\lambda_{\\text{MLE}} = \\frac{n}{\\sum_{i=1}^n \\frac{(x_i - \\mu_{\\text{MLE}})^2}{\\mu_{\\text{MLE}}^2 x_i}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (7.5 marks)\n",
    "Suppose that we know that the random variable $X{\\,\\sim\\,}\\mathcal{Dist}(\\mu=\\theta, \\sigma^2=\\theta^2)$ follows the PDF given below:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f\\left(x|\\theta\\right)=\n",
    "\\begin{cases}\n",
    "\\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta}) & x > 0 \\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Given a sample of $n$ [i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) observations $\\mathbf{x}=$ $\\left(x_{1}, \\ldots, x_{n}\\right)$ from this distribution, please answer the following questions:\n",
    "\n",
    "**(a)** Derive the MLE estimator for $\\theta$, i.e., $\\hat{\\theta}_{\\text{MLE}}$, and show that it is unbiased. [2.5 Marks]\n",
    "\n",
    "**(b)** Find an estimator with better MSE (i.e smaller MSE) compared to the $\\hat{\\theta}_{\\text{MLE}}$ obtained from (a). [5 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "\n",
    "(a) To Derive MLE estimator for  $\\theta$, i.e., $\\hat{\\theta}_{\\text{MLE}}$, and show that it is unbiased: \n",
    "\n",
    "Given: \n",
    "The Probability Density Function is as follows: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f\\left(x|\\theta\\right)=\n",
    "\\begin{cases}\n",
    "\\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta}) & x > 0 \\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### Step 1: Writing likelihood Function for the PDF: \n",
    "\n",
    "We know that likelihood function is given by $L\\left(x|\\theta\\right) = \\prod_{i=1}^n f(x_i | \\theta)$ substituting this to the pdf we get: \n",
    "\n",
    " $$L\\left(x|\\theta\\right) = \\prod_{i=1}^n \\left(\\frac{1}{\\theta} \\exp\\left(-\\frac{x_i}{\\theta}\\right)\\right)$$   \n",
    "  $$= \\left(\\frac{1}{\\theta}\\right)^n \\exp\\left(-\\frac{\\sum_{i=1}^n x_i}{\\theta}\\right)$$\n",
    "\n",
    "### Step 2: Now we find negative log-likelihood: \n",
    "$$-L\\left(x|\\theta\\right)= - \\log L\\left(x|\\theta\\right)$$  \n",
    "$$-L\\left(x|\\theta\\right) = - \\log \\left( \\left(\\frac{1}{\\theta}\\right)^n \\exp\\left(-\\frac{\\sum_{i=1}^n x_i}{\\theta}\\right) \\right)$$  \n",
    "\n",
    "by applying property of logarithms $ \\ln(a \\cdot b) = \\ln(a) + \\ln(b) $, we get:\n",
    "$$-L\\left(x|\\theta\\right)= - \\left( n \\log\\left(\\frac{1}{\\theta}\\right) - \\frac{\\sum_{i=1}^n x_i}{\\theta} \\right)$$  \n",
    "\n",
    "$$\n",
    "-L\\left(x|\\theta\\right) = -n \\ln\\left(\\frac{1}{\\theta}\\right) + \\frac{\\sum_{i=1}^n x_i}{\\theta}\n",
    "$$\n",
    "$$\n",
    "-L\\left(x|\\theta\\right) = n \\ln(\\theta) + \\frac{\\sum_{i=1}^n x_i}{\\theta}\n",
    "$$\n",
    "\n",
    "### Step 3: Now we partially derive with respect to Theta \n",
    "\n",
    "To find the MLE, we take the partial derivative of the negative log-likelihood function with respect to $\\theta$ and set it to zero:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} \\left(-L\\left(x|\\theta\\right)\\right) = \\frac{\\partial}{\\partial \\theta} \\left( n \\ln(\\theta) + \\frac{\\sum_{i=1}^n x_i}{\\theta} \\right)\n",
    "$$  \n",
    "\n",
    "Let's compute the derivative step by step:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} \\left( n \\ln(\\theta) \\right) = \\frac{n}{\\theta}\n",
    "$$  \n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} \\left( \\frac{\\sum_{i=1}^n x_i}{\\theta} \\right) = -\\frac{\\sum_{i=1}^n x_i}{\\theta^2}\n",
    "$$  \n",
    "\n",
    "Summing these results:\n",
    "$$\n",
    "\\frac{n}{\\theta} - \\frac{\\sum_{i=1}^n x_i}{\\theta^2} = 0\n",
    "$$  \n",
    "\n",
    "Multiplying through by $\\theta^2$:\n",
    "$$\n",
    "n\\theta - \\sum_{i=1}^n x_i = 0\n",
    "$$  \n",
    "$$\n",
    "n\\theta = \\sum_{i=1}^n x_i\n",
    "$$  \n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\frac{\\sum_{i=1}^n x_i}{n}\n",
    "$$  \n",
    "\n",
    "Now we Show that $\\theta_{\\text{MLE}}$ is Unbiased \n",
    "\n",
    "### An estimator $\\hat{\\theta}$ is unbiased if $ \\mathbb{E}[\\hat{\\theta}] = \\theta $.\n",
    "\n",
    "Here, $\\theta_{\\text{MLE}} = \\frac{\\sum_{i=1}^n x_i}{n} $.\n",
    "\n",
    "Since $ x_i \\sim \\text{Dist}(\\mu = \\theta, \\sigma^2 = \\theta^2) $, we have:\n",
    "$$\\mathbb{E}[x_i] = \\theta $$  \n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\theta_{\\text{MLE}}\\right] = \\mathbb{E}\\left[\\frac{\\sum_{i=1}^n x_i}{n}\\right]\n",
    "$$  \n",
    "$$\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}[x_i]\n",
    "$$  \n",
    "$$\n",
    "= \\frac{1}{n} \\cdot n \\cdot \\theta\n",
    "$$  \n",
    "$$\n",
    "= \\theta\n",
    "$$  \n",
    "\n",
    "#### Thus, $\\theta_{\\text{MLE}}$ is an unbiased estimator of $\\theta$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (7.5 marks)\n",
    "Suppose that we know that a random variable $X$ follows the distribution given below:\n",
    "\n",
    "$$\n",
    "f\\left(x|\\theta\\right)= \\frac{{2 \\choose x}\\theta^x\\left(1-\\theta\\right)^{2-x}}{1-\\left(1-\\theta\\right)^2}, \\; x= \\{1,2\\}\n",
    "$$\n",
    "\n",
    "Imagine that we observe a sample of $\\textbf{n}$ [i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) random varaibles $\\mathbf{x}=$ $\\left(x_{1}, \\ldots, x_{n}\\right)$ and want to model them using this distribution. Please use the concept of maximum likelihood to estimate for the parameter $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "\n",
    "Given the pdf: \n",
    "$$\n",
    "f\\left(x|\\theta\\right)= \\frac{{2 \\choose x}\\theta^x\\left(1-\\theta\\right)^{2-x}}{1-\\left(1-\\theta\\right)^2}, \\; x= \\{1,2\\}\n",
    "$$ \n",
    "\n",
    "### Step 1: Likelihood Function:\n",
    "We first find the likelihood function for it. \n",
    "W.K.T likelihood fucntion is given by: \n",
    "$$L(x\\theta) = \\prod_{i=1}^n f(x_i|\\theta)$$ \n",
    "\n",
    "pluging in the pdf: \n",
    "$$L(x\\theta) = \\prod_{i=1}^n \\frac{(2/x_i) \\theta^{x_i} (1-\\theta)^{2-x_i}}{1 - (1-\\theta)^2}$$ \n",
    "\n",
    "### Step 2: Applying -ve log-Likelihood: \n",
    "Now we find the negative log-likelihood. \n",
    "$$L(x\\theta) = -\\log L(\\theta) = -\\sum_{i=1}^n \\log \\left( \\frac{(2/x_i) \\theta^{x_i} (1-\\theta)^{2-x_i}}{1 - (1-\\theta)^2} \\right)$$  \n",
    "\n",
    "Applying the properties of logarithms we get: \n",
    "\n",
    "$$= -\\sum_{i=1}^n \\left( \\log \\left( \\frac{2}{x_i} \\right) + x_i \\log (\\theta) + (2-x_i) \\log (1-\\theta) - \\log \\left( 1 - (1-\\theta)^2 \\right) \\right)$$  \n",
    "$$= -\\sum_{i=1}^n \\left( \\log \\left( \\frac{2}{x_i} \\right) + x_i \\log (\\theta) + (2-x_i) \\log (1-\\theta) - \\log \\left( \\theta (2-\\theta) \\right) \\right)$$   \n",
    "\n",
    "### Step 3: Partially deriving with respect to theta: \n",
    "\n",
    "Now in order to find MLE with respect to $\\theta$ we consider the partial dervative with respect to it by susbtiuting the partial dervative equation to zero. \n",
    "\n",
    "$$\\frac{\\partial (-L(x|\\theta))}{\\partial \\theta} = -\\sum_{i=1}^n \\left( \\frac{x_i}{\\theta} - \\frac{(2-x_i)}{1-\\theta} - \\frac{1-\\theta - \\theta}{\\theta (2-\\theta)} \\right)$$  \n",
    "\n",
    "$$= \\sum_{i=1}^n \\left( -\\frac{x_i}{\\theta} + \\frac{(2-x_i)}{1-\\theta} + \\frac{2}{\\theta (2-\\theta)} \\right)$$  \n",
    "\n",
    "setting partial dervative equation to zero we get: \n",
    "$$\\sum_{i=1}^n \\left( -\\frac{x_i}{\\theta} + \\frac{(2-x_i)}{1-\\theta} + \\frac{2}{\\theta (2-\\theta)} \\right) = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (7.5 marks)\n",
    "Suppose that we know that the random variable $X$ follows the PDF given below:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    f\\left(x|\\theta\\right)= \n",
    "    \\begin{cases}\n",
    "         e^{-(x-\\theta)} & x\\geq\\theta \\\\\n",
    "         0 & \\text{otherwise.}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Given a sample of $n$ [i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) observations $\\mathbf{x}=$ $\\left(x_{1}, \\ldots, x_{n}\\right)$ from this distribution, please answer the following questions:\n",
    "\n",
    "**(a)** Derive the MLE estimator for $\\theta$, i.e., $\\hat{\\theta}_{\\text{MLE}}$. [4.5 Marks]\n",
    "\n",
    "**(b)** Show that the estimator $\\hat{\\theta} = \\overline{X} - 1$ (where $\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$) is an unbiased and consistent estimator for the given distribution. [3 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "\n",
    "(a) Given PDF function: \n",
    "$$\n",
    "\\begin{equation}\n",
    "    f\\left(x|\\theta\\right)= \n",
    "    \\begin{cases}\n",
    "         e^{-(x-\\theta)} & x\\geq\\theta \\\\\n",
    "         0 & \\text{otherwise.}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We need to derrive the MLE estimator for theta. \n",
    "\n",
    "### Step 1: Applying Likelihood Function for the PDF: \n",
    "\n",
    "W.K.T likelihood function is given by  $$L(x\\theta) = \\prod_{i=1}^n f(x_i|\\theta)$$ \n",
    "\n",
    "applying for PDF: \n",
    "$$L(\\theta) = \\prod_{i=1}^n e^{-(x_i - \\theta)} \\quad \\text{for } x_i \\geq \\theta$$  \n",
    "Since the likelihood is zero in case of any $(x_i < \\theta)$,  and hence we only consider the case where all $(x_i \\geq \\theta)$  \n",
    "$$L(\\theta) = e^{-\\sum_{i=1}^n (x_i - \\theta)} = e^{-\\sum_{i=1}^n x_i + n\\theta}$$ \n",
    "\n",
    "### Step 2: Taking Negative Log Likelihood:\n",
    "$$L(\\theta) = -\\log L(\\theta) = -\\log \\left( e^{-\\sum_{i=1}^n x_i + n\\theta} \\right) = \\sum_{i=1}^n x_i - n\\theta$$ \n",
    "\n",
    "### Step 3: Partially deriving Negative Log Likelihood with respect to Theta: \n",
    "$$\\frac{\\partial (-L(\\theta))}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( \\sum_{i=1}^n x_i - n\\theta \\right) = -n$$ \n",
    "\n",
    "Since the dervative of -n is a constant which does not depend on $\\theta$, the negative log likelihood function is only minimized when value of $\\theta$ is large for all $(x_i \\geq \\theta)$ therefore \n",
    " $$ \n",
    "\\hat{\\theta}_{\\text{MLE}} = \\min(x_i)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Confidence Interval Estimation & Central Limit Theorem (30 marks)\n",
    "**WARNING:** If it is not explicitly stated, please assume the 95% confidence or 5% significant level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (5 marks)\n",
    "The [SETU](https://www.monash.edu/ups/setu) score of FIT units is known to follow a $\\mathcal{N}(\\mu=4$, $\\sigma^2=0.25)$ distribution. You take a sample of the units and check their last semester's SETU. How many units do you have to sample to have a 95% confidence interval for $\\mu$ with width 0.1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "#### It is given that the setu score of FIT units follow a normal distribution ->(*) \n",
    "1.And the variance of these setu score is $\\sigma^2 = 0.25$.   \n",
    "2.Mean $\\mu$ of the scores is given by 4.  \n",
    "3.We also know that the 95% confidence interval is given for $\\mu$ at the width of 0.1.  \n",
    "4.Given variance the standard deviation will be $\\sigma=\\sqrt{0.25} = 0.5$\n",
    "\n",
    "From equation(*) we know that the score follows a normal distribution and $\\sigma^2$ & $\\mu$ are given and hence \n",
    "we consider $$\\bar{X} \\pm Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$$  \n",
    "\n",
    "Therefore CI can be expanded as \n",
    "$$ CI = (\\bar{X} + z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}, \\bar{X} - z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}})$$\n",
    "\n",
    "From number 3 in given we write the above equation as follows:   \n",
    "$$(\\bar{X} + z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}-( \\bar{X} - z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}})) = 0.1$$\n",
    "\n",
    "Subsituting the values we get  \n",
    "$$(4 + z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}-( 4 - z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}})) = 0.1$$\n",
    "$$(4 + z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}- 4 + z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}) = 0.1$$\n",
    "$$2 *( z_{\\frac{\\alpha}{2}}*\\frac{\\sigma}{\\sqrt{n}}) = 0.1$$  \n",
    "Since we need to find the sample space we re-arrange the above equation with respect to ${\\sqrt{n}}$  \n",
    "$$ 2* \\frac{Z_{\\frac{\\alpha}{2}}*\\sigma}{0.1} =\\sqrt{n} $$  \n",
    "Simplifying the above equation we get  \n",
    "$$ n = {20*Z_{\\frac{\\alpha}{2}}*\\sigma}^2 --->(a)$$  \n",
    "\n",
    "Now we find the value for $Z_{\\frac{\\alpha}{2}}$   \n",
    "The sgnificance value is given by $$ \\alpha = 1-\\frac{95}{100} = 0.05 $$  \n",
    "This remaning 5% is split between 2 tails of the distribution and therefore \n",
    "$$ Z_{\\frac{\\alpha}{2}} = Z_{\\frac{0.05}{2}} = Z_{0.025} $$\n",
    "finding cumulative probability $$ p = 1 - \\frac{\\alpha}{2} = 1 - 0.025 = 0.975 $$  \n",
    "z-table value for p=0.975 for $Z_{0.025}$ is = 1.96.\n",
    "Substituiting all the values to equation (a) we get \n",
    "$$ n= {20*1.96*0.5}^2 $$\n",
    "$$ n = 384.16 $$\n",
    "rounding $$ n = 385 $$\n",
    "### Thus, We need to smaple 385 units to have 95% confidence interval for$\\mu$ with width of 0.1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (5 marks)\n",
    "You do a poll to see what fraction $p$ of the students participated in the FIT5197 SETU survey. You then take the average frequency of all surveyed people as an estimate $\\hat p$  for $p$. Now it is necessary to ensure that there is at least $99\\%$ certainty that the difference between the surveyed rate $\\hat p$   and the actual rate $p$ is not more than $5\\%$. At least how many people should take the survey?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "Given:   \n",
    "The Question states that there is 99% confidence interval  \n",
    "then the significance value i.e $\\alpha$ is 1% (0.01) and this is split between 2 tails given by $\\frac{\\alpha}{2}$ =0.01/2  \n",
    "Considering standard normal distribution table the value for $Z_{\\frac{0.01}{2}} = Z_{0.005} = 2.576$   \n",
    "In the survey process there are 2 possible outcomes, i.e. a student takes a survey or a student doesn't take a survey,   \n",
    "considering this nature we can relate this to bernouli distribution. The interval is given by   \n",
    "$$ \\hat{p}\\pm Z_{\\frac{\\alpha}{2}}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}}$$   \n",
    "\n",
    "The maximum diference between the surveyed rate and actual rate is not more than 5%, and we can consider that as,   \n",
    "$$ M = Z_{\\frac{\\alpha}{2}}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}}$$\n",
    "\n",
    "We need to find the number people that needs to take the survey, which is the sample space. Hence we arrange the above as followed. \n",
    "$$ M = Z_{\\frac{\\alpha}{2}}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}}$$\n",
    "By taking square root on both side   \n",
    "$$ M^2 = (Z_{\\alpha/2})^2\\frac{\\hat{p}(1-\\hat{p})}{n}$$ \n",
    "\n",
    "to solve for sample space,  \n",
    "$$ n = \\frac{(Z_{\\alpha/2})^2{\\hat{p}(1-\\hat{p})}}{M^2}$$  \n",
    "\n",
    "substituting the values from given \n",
    "$$ n = \\frac{(2.576)^2*{0.5*(1-0.5)}}{0.05}^2$$   \n",
    "\n",
    "$$ n = \\frac{6.635*{0.25}}{0.0025}$$  \n",
    "$$ n = 663.5$$  \n",
    "rounding up $$ n = 664$$  \n",
    "\n",
    "### to ensure that there is at least  99% certainty that the difference between the surveyed rate  ð‘Ì‚ and the actual rate  ð‘ is not more than 5%, at least 664 people should take the survey. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (5 marks)\n",
    "Suppose you repeated the above polling process multiple times and obtained $100$ confidence intervals, each with confidence level of $99\\%$. About how many of them would you expect to be \"wrong\"? That is, how many of them would not actually contain the parameter being estimated? Should you be surprised if $4$ of them are wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (5 marks)\n",
    "\n",
    "Consider the random variable $X$ following the Bernoulli distribution with a parameter $\\theta$, i.e., $X\\sim \\text{Be}(\\theta)$, where $\\theta=0.9$. Given that you collect $n$ random variable $X_1, X_2,\\ldots, X_n$. Calculate the smallest sample size, ${n}$, you have to observe to guarantee that\n",
    "\n",
    "$$\n",
    "P\\left(\\left|\\frac{\\sum_1^n X_i}{n} - \\theta \\right| >0.01\\right) < 0.1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "Given: \n",
    "For a Bernoulli distribution we can consider the following:   \n",
    " 1. $X\\sim \\text{Be}(\\theta) = 0.9$   \n",
    " 2. $\\mu$  $ of X\\sim: \\mu = \\theta = 0.9$   \n",
    " 3. $Variance$ $\\sigma^2 of X\\sim: \\sigma^2 = \\theta(1-\\theta) = 0.9(1-0.9)= 0.09$\n",
    " \n",
    "By considering central limit theorem, we know that the sample mean of n independent and identically distributed random variables is normally distributed, hence we consider the below.  \n",
    "$$\\sum x \\sim \\mathcal{N}(\\theta, \\sigma / n)$$  \n",
    "$$=\\mathcal{N}(0.9, 0.09 / n)$$  \n",
    "The Standard deviation is given by   \n",
    "$$\\sigma = \\sqrt{\\frac{\\sigma^2}{n}}$$  \n",
    "$$ = \\sqrt{\\frac{0.09}{n}}$$  \n",
    "$$\\sigma = {\\frac{0.3}{\\sqrt n}}$$  \n",
    "\n",
    "We need to find the below probability: \n",
    "$$\n",
    "P\\left(\\left|\\frac{\\sum_1^n X_i}{n} - \\theta \\right| >0.01\\right) < 0.1.\n",
    "$$  \n",
    "\n",
    "$P(\\frac{\\sum_1^n X_i}{n})$ can be considered as the sample mean $\\bar{X}$ sustituting the values we get the following, \n",
    "$$P(\\left|\\bar{X} - 0.9 \\right| <= 0.01) > 0.9$$\n",
    "\n",
    "Now we find the Z score for the sample mean \n",
    "Wkt $ Z = \\frac {(\\bar X - \\theta)}{\\sigma}$\n",
    "\n",
    "We need to evaulate $$P\\left(\\left|\\frac {(\\bar X - 0.9)}{\\sigma}\\right| <= \\frac{0.01}{\\sigma}\\right) > 0.9$$\n",
    "$$P\\left(\\left|Z\\right| <= \\frac{0.01}{\\frac{0.3}{\\sqrt n}}\\right) > 0.9----->(B)$$ \n",
    "\n",
    "We now need to find the critical value of Z. for a 90% confidence interval the data is within the interval and rest 10% lies out which is divided between the 2 tails i.e. 5% (0.05) in each tail. We need to find Z score corresponding to 0.95(CI 0.90 + 0.5 tail). \n",
    "\n",
    "From the Z table we can find the cumulative probability for the given Z-scores $Z_{0.95}$ the value is 1.645. \n",
    "Considering equation B now we solve for n: \n",
    "$$\\frac{0.01 \\sqrt{n}}{0.3} > 1.645$$  \n",
    "$$ \\frac{0.01 \\sqrt{n}} > 0.4935$$\n",
    "$$\\sqrt{n} > 49.35$$\n",
    "applying square root on both side\n",
    "$$(\\sqrt n)^2 > (49.35)^2$$ \n",
    "$$ n > 2435.42$$ \n",
    "$$ n = 2436$$ \n",
    "### Therefore the smallest sample size to guarantee $P\\left(\\left|\\frac{\\sum_1^n X_i}{n} - \\theta \\right| >0.01\\right) < 0.1$ is 2436."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (5 Marks)\n",
    "\n",
    "The error for the production of a machine is uniformly distribute over [-0.75, 0.75] unit. Assuming that there are 100 machines working at the same time, approximate the probability that the final production differ from the exact production by more than 4.5 unit?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "Given:  \n",
    "1.The error for the prodcution is uniformly distributed -> (*)   \n",
    "2.Error distribution range $[-0.75, 0.75]$  \n",
    "3.Number of machines working at the same time n = 100   \n",
    "4.We need to find what is the PROBABILITY that the final production differ from the exact production by more than 4.5 units.  \n",
    "We know that the error distribution range is given by $[-0.75, 0.75]$, For a Uniform distribution of the form U(a,b) where a = -0.75 and b=0.75 the mean $\\mu$ and $\\sigma^2$ is given as follows   \n",
    "$$ \\mu = \\frac{a+b}{2}$$ & $$\\sigma^2 = \\frac{{b-a}^2}{12}$$   \n",
    "\n",
    "substituting the values for a and b we get $$ \\mu\\frac{-0.75+0.75}{2} = 0 $$ & $$ \\sigma^2 = \\frac{{1.5}^2}{12} = 0.1875 $$ \n",
    "$$ \\sigma = \\sqrt{0.1875} $$     \n",
    "\n",
    "For independent and identically distributed random variables with mean $\\mu$ and standard deviation $\\sigma^2$ the sum of errors according to CLT is given by: \n",
    "$$ \\sum x \\approx \\mathcal{N}(n\\mu,n\\sigma^2) $$  \n",
    "Substituting the values we get   \n",
    "$$ \\sum x \\approx \\mathcal{N}(100(0), 100(0.1875)) $$\n",
    "$$ \\sum x \\approx \\mathcal{N}(0, 18.75) $$   \n",
    "\n",
    "from the above standard deviation can derived as $$ \\sigma = \\sqrt{18.75}\\approx 4.33 $$  \n",
    "\n",
    "Now let's find the probability of the difference in the production that deviates more than 4.5 units, \n",
    "For 100 machines and in the distribution considering the 2 tails we can define the probability as follows: \n",
    "\n",
    "$$P(S_{100} > 4.5) = P(S_{100} > 4.5) + P(S_{100} < -4.5)---->(A)$$\n",
    "\n",
    "First we find the Z score given by \n",
    "$$ Z = \\frac{S-\\sigma}{\\mu}$$ \n",
    "$$Z = \\frac{4.5-0}{4.33} = \\frac{4.5}{4.33}$$ \n",
    "\n",
    "$$Z \\approx 1.04$$  & \n",
    "\n",
    "\n",
    "$$Z = \\frac{-4.5-0}{4.33} = \\frac{-4.5}{4.33}$$ \n",
    "\n",
    "$$Z \\approx 1.04$$\n",
    "\n",
    "Using standard normal distribution tables, we find probability for the Z scores   \n",
    "i)$for Z > 1.04:$ $P(Z>1.04) \\approx 0.1492$  \n",
    "\n",
    "ii)$for Z < -1.04:$ $P(Z>1.04) \\approx 0.1492$\n",
    "\n",
    "Substituting and combining values to equation A we get: \n",
    "$$P(S_{100} > 4.5) = 0.1492 + 0.1492$$    \n",
    "$$P(S_{100} > 4.5) = 0.2984$$   \n",
    "\n",
    "#### Therefore the probability that the final production differ from the exact production by more than 4.5 unit is 0.2984 or 29.84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (5 Marks)\n",
    "\n",
    "Let $X_{1}, X_{2}, \\ldots, X_{n}$ be a random sample from a Poisson distribution with mean\n",
    "$\\lambda .$ Thus, $Y=\\sum_{i=1}^{n} X_{i}$ has a Poisson distribution with mean $n \\lambda .$ Moreover, by the Central limit Theorem, $\\bar{X}=Y / n$ has, approximately, a Normal $(\\lambda, \\lambda / n)$ distribution for large $n$. Show that for large values of $n,$ the distribution of\n",
    "$$\n",
    "2 \\sqrt{n}\\left(\\sqrt{\\frac{Y}{n}}-\\sqrt{\\lambda}\\right)\n",
    "$$\n",
    "is independent of $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "\n",
    "Given:   \n",
    "X1, X2,....Xn are i.i.d random variables of a poisson distribution with mean $\\lambda$   \n",
    "$Y=\\sum_{i=1}^{n} X_{i}$ has a Poisson distribution with mean $ \\lambda $  \n",
    "by CLT $\\bar{X}=Y / n$ has, approximately, a Normal $(\\lambda, \\lambda / n)$ \n",
    "\n",
    "$$\n",
    "2 \\sqrt{n}\\left(\\sqrt{\\frac{Y}{n}}-\\sqrt{\\lambda}\\right)\n",
    "$$\n",
    "to check is independent of $\\lambda$. \n",
    "\n",
    "First we consider the CLT for $\\bar{X}$ \n",
    "\n",
    "We know that Y is the sum of n i.i.d. in Poisson $\\lambda$ random variables,  Y follows a Poisson distribution with mean $ \\lambda$. Considering the sample mean $\\bar{X} = \\frac{Y}{n}$ is normally distributed:\n",
    "$$\n",
    "\\bar{X} \\sim N\\left( \\lambda, \\frac{\\lambda}{n} \\right)---->(*)$$ \n",
    "Hence, $Y \\sim N\\left( n\\lambda, n\\lambda \\right)$ for all large n. \n",
    "\n",
    "Consider $W = \\sqrt{\\frac{Y}{n}}$. so that we can show  the distribution of $( 2\\sqrt{n} (W - \\sqrt{\\lambda})$ is independent of $\\lambda$\n",
    "\n",
    "Now in order to approximate the distribution we apply Delta Method which helps to find distribution fucntion of a random variable. \n",
    "\n",
    "$$W = \\sqrt{\\bar{X}} \\approx \\sqrt{\\lambda} + \\frac{1}{2\\sqrt{\\lambda}} (\\bar{X} - \\lambda)$$\n",
    "\n",
    "$$W = \\sqrt{\\lambda} + \\frac{1}{2\\sqrt{\\lambda}} (\\bar{X} - \\lambda)$$\n",
    "\n",
    "Now we consider $( 2\\sqrt{n} (W - \\sqrt{\\lambda})$  \n",
    "substituting the W to the above we get \n",
    "$$2\\sqrt{n} (W - \\sqrt{\\lambda}) = 2\\sqrt{n} \\left( \\sqrt{\\lambda} + \\frac{1}{2\\sqrt{\\lambda}} (\\bar{X} - \\lambda) - \\sqrt{\\lambda} \\right)$$ \n",
    "\n",
    "$$= 2\\sqrt{n} \\cdot \\frac{1}{2\\sqrt{\\lambda}} (\\bar{X} - \\lambda)$$  \n",
    "\n",
    "$$= \\sqrt{n} \\cdot \\frac{1}{\\sqrt{\\lambda}} (\\bar{X} - \\lambda)$$\n",
    "$$= \\frac{\\sqrt{n}}{\\sqrt{\\lambda}} (\\bar{X} - \\lambda)---->(1)$$ \n",
    "\n",
    "W.k.t from equation (*) $$\\bar{X} \\sim N(\\lambda, \\frac{\\lambda}{n})$$, thus:\n",
    "$$\n",
    "\\frac{\\bar{X} - \\lambda}{\\sqrt{\\frac{\\lambda}{n}}} \\sim N(0, 1) ---->(2)\n",
    "$$ \n",
    "\n",
    "By considering equation 1,2 and (*) we can conclude \n",
    "$$\n",
    "\\frac{\\sqrt{n}}{\\sqrt{\\lambda}} (\\bar{X} - \\lambda) = \\frac{\\bar{X} - \\lambda}{\\sqrt{\\frac{\\lambda}{n}}} \\sim N(0,1) $$ \n",
    "\n",
    "\n",
    "$\n",
    "2 \\sqrt{n}\\left(\\sqrt{\\frac{Y}{n}}-\\sqrt{\\lambda}\\right)\n",
    "$is independent of $\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Hypothesis Testing (15 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (7.5 marks)\n",
    "\n",
    "As a motivation for students to attend the tutorial, Levin is offering a lot of hampers this semester. He has designed a spinning wheel (This is an example https://spinnerwheel.com/) where there are four choices on it: \"Hamper A\", \"Hamper B\", \"Hamper C\", and \"Better Luck Next Time\". These choices are evenly distributed on the wheel. If a student completes the attendance form for one of the tutorials, they will get a chance to spin the wheel. \n",
    "\n",
    "As a hard-working student yourself, you have earned 12 chances at the end of the semester. When you finished your spins, the result showed \\{\"N\", \"A\", \"N\", \"N\", \"B\", \"C\", \"N\", \"N\", \"N\", \"A\", \"A\", \"N\"\\} (\"A\",\"B\" and \"C\" denote three hampers respectively, while \"N\" denotes \"Better Luck Next Time\"). You are shocked by the result and feel the game might be faulty. Before questioning Levin, you would like to perform a hypothesis test to check whether you are really unlucky or has Levin secretly done something that had influenced the probability of winning or not. State your hypothesis, perform the test and interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER \n",
    "\n",
    "The goal here will be to check if the results of the spining wheel is fair or not. \n",
    "First we will set up our hypothesis: \n",
    "1. Our Null Hypothesis H0 is given as: \"The spining wheel has an equal probability of 0.25 and is fair\" \n",
    "2. Our Alternate Hypothesis H1 is given as:\"The spining wheel has unequal probability and in unfair\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (7.5 marks)\n",
    "\n",
    "The operation team of a retailer is about to report the performance of year 2022. As the data analyst, your job entails reviewing the reports provided by the team. One of the reports regarding membership subscription looks suspicous to you. In this report, they compared the amount of money spent by the members against the non-members over the year. The methodology is that they randomly selected 20 customers and compared their spending before and after becoming a member. \n",
    "\n",
    "The average spending before becoming a member is $\\$88.5$ per week with a standard deviation of $\\$11.2$. The average after becoming a member is $\\$105$ per week with a standard deviation of $\\$15$. In the report, the retailer claimed that after becoming a member, customers tend to spend $10\\%$ more than before on average.\n",
    "\n",
    "As a statistician, you decide to perform a hypothesis test to verify the veracity of this claim. State your hypothesis, perform\n",
    "the test and interpret the result. Additionally, please suggest another methodology to compare member vs non-member."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "\n",
    "Here we need check whether a cutomer tends to spend 10% more on average after becoming a member \n",
    "1. Our Null Hypothesis(H0): There is no difference in typical spending before and after membership. \n",
    "2. Our Alter Hypothesis(H1): The average spending after becoming a member exceeds the average spending 10% before becoming a member. \n",
    "\n",
    "therefore $$ H0 = \\mu_d = 0$$ and\n",
    "$$ H1 = \\mu_d > 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 Simulation (25 marks) - no external libraries R allowed. Only base packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are involved in a scientific research project. Your lab mates are struggling with a sampling problem. They have a probability density function as shown below, but none of them knows how to generate random numbers from this probability distribution. As a member with a background in data science in this lab, you want to help them solve the sampling problem.\n",
    "$$ f(x) = \n",
    "   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      4x+1 &  -\\frac{1}{4}\\leq x\\lt 0 \\\\\n",
    "      -\\frac{4}{7}x+1 & 0 \\leq x \\lt \\frac{7}{4}\\\\\n",
    "      0 & \\mathrm{otherwise}\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "**(a)** First of all, you want to calculate the cumulative density function $F(x)$ and the quantile function $Q(p)$ for $f(x)$. \n",
    "\n",
    "**(b)** You can get random numbers distributed as per $f(x)$ by generating uniformly distributed numbers $p$ from 0 to 1 and plug them into $Q(p)$. You know computer simulation helps a lot so you want to write a function to generate random numbers distributed as per $f(x)$. You call this function ``samplingHelper`` and it takes a single input **n** to be the number of realizations you want to generate. Besides, you want to use the following function template. The better your function is (errors handling, comments, variable names, etc) the higher the score you will get for this part.\n",
    "\n",
    "```{r}\n",
    "samplingHelper <- function(n) {\n",
    "    # Put down your own code here\n",
    "    \n",
    "    return(numbers) # numbers is an array of random numbers you generated as per f(x)\n",
    "}\n",
    "```\n",
    "\n",
    "**(c)** You want to call ``samplingHelper`` to generate 99,999 random numbers as per $f(x)$ and plot a histogram of the sample with 100 bins as well as overlay a theoretical curve on top of it.\n",
    "\n",
    "**(d)** You know sharing knowledge is a good practise. You want to summarize the key steps of your sampling method. More importantly, you want to justify why this sampling method works. (less than 250 words)\n",
    "\n",
    "**(e)** Your lab mates all appreciate your help and they get stuck on another sampling problem. The probability density function is given below\n",
    "$$\n",
    "f(x) = e^{-x^2\\pi} \\text{ for x } \\in [-\\infty, +\\infty]\n",
    "$$\n",
    "They need your help to generate random numbers as per this distribution. You decide to use the same sampling strategy as you discussed above. Now you want to derive its cumulative density function $F(x)$ and the Quantile function $Q(p)$.\n",
    "\n",
    "**(f)** You want to implement it as another function called ``newSamplingHelper``. It takes a single input **n** to be the number of realizations you want to generate. Besides, you want to use the following function template. The better your function is (errors handling, comments, variable names, etc) the higher the score you will get for this part.\n",
    "\n",
    "```{r}\n",
    "newSamplingHelper <- function(n) {\n",
    "    # Put down your own code here\n",
    "    \n",
    "    return(numbers) # numbers is an array of random numbers you generated as per f(x)\n",
    "}\n",
    "```\n",
    "\n",
    "**(g)** You want to call ``newSamplingHelper`` to generate 99,999 random numbers as per $f(x)$ and plot a histogram of the sample with 100 bins as well as overlay a theoretical curve on top of it. What's your findings by comparing it with Gaussian distribution? (less than 100 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "\n",
    "(a) calculating the cumulative density function  ð¹(ð‘¥) and the quantile function  ð‘„(ð‘) for ð‘“(ð‘¥). \n",
    "Given: \n",
    "$$ f(x) = \n",
    "   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      4x+1 &  -\\frac{1}{4}\\leq x\\lt 0 \\\\\n",
    "      -\\frac{4}{7}x+1 & 0 \\leq x \\lt \\frac{7}{4}\\\\\n",
    "      0 & \\mathrm{otherwise}\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$ \n",
    "\n",
    "1. Considering the First Interval $( -\\frac{1}{4} \\leq x < 0 )$ \n",
    "$$\n",
    "F(x) = \\int_{-\\frac{1}{4}}^x (4t + 1) \\, dt\n",
    "$$  \n",
    "$$\n",
    "F(x) = [2t^2 + t]_{-\\frac{1}{4}}^x $$  \n",
    "\n",
    "$$F(x) = \\left( 2x^2 + x \\right) - \\left( 2\\left( -\\frac{1}{4} \\right)^2 + \\left( -\\frac{1}{4} \\right) \\right) $$ \n",
    "\n",
    "$$ F(x) = 2x^2 + x - \\left( 2\\left( \\frac{1}{16} \\right) - \\frac{1}{4} \\right) $$\n",
    "$$ F(x) = 2x^2 + x - \\left( \\frac{1}{8} - \\frac{2}{8} \\right) $$\n",
    "$$ F(x) = 2x^2 + x - \\left( -\\frac{1}{8} \\right)$$ \n",
    "$$ F(x) = 2x^2 + x + \\frac{1}{8}$$ \n",
    "\n",
    "2. Considering the Second Interval $( 0 \\leq x < \\frac{7}{4} )$ \n",
    " First let's consider $( F(x) ) at ( x = 0 )$ \n",
    " $F(0) = 2(0)^2 + 0 + \\frac{1}{8} = \\frac{1}{8}$\n",
    "\n",
    "Next, we integrate from 0 to  x :  \n",
    "$$F(x) = \\frac{1}{8} + \\int_{0}^x \\left( -\\frac{4}{7}t + 1 \\right) dt$$ \n",
    "$$ F(x) = \\frac{1}{8} + \\left[ -\\frac{2}{7}t^2 + t \\right]_{0}^x $$\n",
    "$$ F(x) = \\frac{1}{8} + \\left( -\\frac{2}{7}x^2 + x \\right) $$\n",
    "$$ F(x) = \\frac{1}{8} - \\frac{2}{7}x^2 + x $$  \n",
    "Therefore the cumulative distribution function \\( F(x) \\) is given as follows :\n",
    "$$ F(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{for } x < -\\frac{1}{4} \\\\\n",
    "2x^2 + x + \\frac{1}{8} & \\text{for } -\\frac{1}{4} \\leq x < 0 \\\\\n",
    "\\frac{1}{8} - \\frac{2}{7}x^2 + x & \\text{for } 0 \\leq x < \\frac{7}{4} \\\\\n",
    "1 & \\text{for } x \\geq \\frac{7}{4}\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "\n",
    "Now We calculate the quantile function Q(p): \n",
    "\n",
    "Considering CDF has derived from above we can write: \n",
    "\n",
    "For the First interval from the CDF:$(-\\frac{1}{4} \\leq x < 0 )$\n",
    "The CDF is given by: \n",
    "$$F(x) = 2x^2 + x + \\frac{1}{8}$$ \n",
    "\n",
    "We need to solve for  x in terms of  p :\n",
    "$$ 2x^2 + x + \\frac{1}{8} = p $$\n",
    "$$ 2x^2 + x + \\frac{1}{8} - p = 0 ----(D) $$ \n",
    "\n",
    "Since above equation D is of the quadratic form, we can consider the quadratic equation formula. \n",
    "$$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a})$$ \n",
    "Plugging in the values we get \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{1 - 4 \\cdot 2 \\cdot (\\frac{1}{8} - p)}}{2 \\cdot 2}$$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{1 - 1 + 8p}}{4} $$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{8p}}{4} $$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm 2\\sqrt{2p}}{4} $$\n",
    "$$\n",
    "x = \\frac{-1 + 2\\sqrt{2p}}{4} $$ \n",
    " Considering the interval where x lies we only take +ve part of equation. \n",
    "$$ x = -\\frac{1}{4} + \\frac{\\sqrt{2p}}{2} $$  \n",
    "\n",
    "For the interval $ (0 \\leq x < \\frac{7}{4}) $\n",
    "The CDF for this interval is given as follows: \n",
    "$$\n",
    "F(x) = \\frac{1}{8} - \\frac{2}{7}x^2 + x $$ \n",
    "\n",
    " solving for x in terms of p:\n",
    "$$ \n",
    "\\frac{1}{8} - \\frac{2}{7}x^2 + x = p $$\n",
    "$$\n",
    "-\\frac{2}{7}x^2 + x + \\frac{1}{8} - p = 0 $$ \n",
    "\n",
    "Above is another equation in quadratic form and hence we consider the same quadratic equation. \n",
    "$$ x = \\frac{-1 \\pm \\sqrt{1 - 4 \\cdot \\left(-\\frac{2}{7}\\right) \\cdot \\left(\\frac{1}{8} - p\\right)}}{2 \\cdot -\\frac{2}{7}}\n",
    "$$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{1 + \\frac{8}{7} \\cdot \\left(\\frac{1}{8} - p\\right)}}{-\\frac{4}{7}} $$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{1 + \\frac{1}{7} - \\frac{8p}{7}}}{-\\frac{4}{7}}$$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{\\frac{8}{7} - \\frac{8p}{7}}}{-\\frac{4}{7}}$$ \n",
    "$$\n",
    "x = \\frac{-1 \\pm \\sqrt{\\frac{8(1 - p)}{7}}}{-\\frac{4}{7}}$$ \n",
    "\n",
    "Multiplying the numerator and denominator by 7:\n",
    "$$\n",
    "x = \\frac{7 \\left(-1 \\pm \\sqrt{\\frac{8(1 - p)}{7}}\\right)}{-4} $$\n",
    "$$\n",
    "x = \\frac{7}{4} \\left(1 \\pm \\sqrt{\\frac{8(1 - p)}{7}}\\right)$$ \n",
    "\n",
    "Considering the interval where x lies we only take +ve part of equation\n",
    "$$\n",
    "x = \\frac{7}{4} \\left(1 - \\sqrt{\\frac{8(1 - p)}{7}}\\right)$$ \n",
    "\n",
    "\n",
    "Therefore the Final CDF and Quantile Function is given by: \n",
    "$$\n",
    "F(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{for } x < -\\frac{1}{4} \\\\\n",
    "2x^2 + x + \\frac{1}{8} & \\text{for } -\\frac{1}{4} \\leq x < 0 \\\\\n",
    "\\frac{1}{8} - \\frac{2}{7}x^2 + x & \\text{for } 0 \\leq x < \\frac{7}{4} \\\\\n",
    "1 & \\text{for } x \\geq \\frac{7}{4}\n",
    "\\end{cases} $$\n",
    "\n",
    "$$\n",
    "Q(p) = \n",
    "\\begin{cases} \n",
    "-\\frac{1}{4} + \\frac{\\sqrt{2p}}{2} & \\text{for } 0 \\leq p < \\frac{1}{8} \\\\\n",
    "\\frac{7}{4} \\left(1 - \\sqrt{\\frac{8(1 - p)}{7}}\\right) & \\text{for } \\frac{1}{8} \\leq p \\leq 1\n",
    "\\end{cases} $$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplingHelper <- function(n) {\n",
    "     p <- runif(n) #Uniform Random Number generation \n",
    "    numbers <- numeric(n) #Vector storage intialisation \n",
    "    #Quantile Function \n",
    "    Q <- function(p) {\n",
    "    if (p < 1/8) {\n",
    "      return(-1/4 + sqrt(2*p)/2)\n",
    "    } else {\n",
    "      return(7/4 * (1 - sqrt((8 * (1 - p))/7)))\n",
    "    }\n",
    "  }\n",
    "    #Applying Quantile Function for uniform random number \n",
    "    for (i in 1:n) {\n",
    "    numbers[i] <- Q(p[i])\n",
    "  }\n",
    "     return(numbers) #Generated number returned. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAA/wBNTU1oaGh8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\nAAEQCUCAf8hj4wtdf1tPAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Sampled Numbers with Theoretical Density\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123) # reproducibility\n",
    "sampled_numbers <- samplingHelper(99999)\n",
    "\n",
    "# Histogram plot with 100 bins\n",
    "hist(sampled_numbers, breaks=100, probability=TRUE, \n",
    "     main=\"Sampled Numbers with Theoretical Density\",\n",
    "     xlab=\"x\", col=\"lightblue\", border=\"black\")\n",
    "\n",
    "#theoretical density function f(x)\n",
    "f <- function(x) {\n",
    "  ifelse(x < -1/4, 0, \n",
    "         ifelse(x < 0, 4 * x + 1, \n",
    "                ifelse(x < 7/4, -4/7 * x + 1, 0)))\n",
    "}\n",
    "\n",
    "# x values sequence for plotting the theoretical density\n",
    "x_vals <- seq(min(sampled_numbers), max(sampled_numbers), length.out=1000)\n",
    "y_vals <- f(x_vals)\n",
    "\n",
    "# theoretical density curve\n",
    "lines(x_vals, y_vals, col=\"green\", lwd=2)\n",
    "\n",
    "#legend\n",
    "legend(\"topright\", legend=c(\"Theoretical Density\"), col=\"green\", lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation \n",
    "\n",
    "(d): While sampling for a given pdf we first derrive the cumulative distribution fucntion at each respective interval, and for the derived CDF we find the inverse of it which is known as the Quantile function. By using the quantile function we can transform the uniform random number to obtain samples from the desired distribution. \n",
    "\n",
    "This sampling method is known as inverse transform sampling as it implements properties of the CDF and it's inverse. \n",
    "The idea here is that, for a uniform random numbers p are transformed using the quantile function Q(p) which ensure the generated numbers follow the specific distribution. \n",
    "Here the quantile function Q(p) accuratley maps the unifrom distribution\n",
    "into desired distribution by taking inverse of the CDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer (e) : \n",
    "Given: \n",
    "The Pdf is given as follows: \n",
    "$$\n",
    "f(x) = e^{-x^2\\pi} \\text{ for x } \\in [-\\infty, +\\infty]\n",
    "$$\n",
    "\n",
    "Step1: Let's Find the CDF for f(x):  \n",
    "The CDF is defined as $f(x) = \\int_{-\\infty}^x f(t) \\, dt$\n",
    "Considering the pdf we solve as follows: \n",
    "$$F(x) = \\int_{-\\infty}^x e^{-t^2 \\pi} \\, dt$$\n",
    "substituting   $u = t \\sqrt{\\pi} )$ , we get:\n",
    "$$F(x) = \\sqrt{\\frac{\\pi}{4}} \\int_{-\\infty}^{x \\sqrt{\\pi}} e^{-u^2} \\, du$$\n",
    "\n",
    "The integral is related to the error function $( \\text{erf}(x) )$:\n",
    "$$ F(x) = \\frac{1}{2} \\left(1 + \\text{erf}(x \\sqrt{\\pi})\\right)$$ \n",
    "\n",
    "where $\\text{erf}(x)$ is defined as:\n",
    "$\n",
    "\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} \\, dt $\n",
    "\n",
    "Therefore, the cumulative distribution function F(x) is:\n",
    "$$\n",
    "F(x) = \\frac{1}{2} \\left(1 + \\text{erf}(x \\sqrt{\\pi})\\right)$$  \n",
    "\n",
    "Now We find the Quantile Function Q(p): \n",
    "Given :\n",
    "Given:\n",
    "$$\n",
    "p = F(x) = \\frac{1}{2} \\left(1 + \\text{erf}(x \\sqrt{\\pi})\\right)$$\n",
    "\n",
    "We solve for  x  in terms of  p :\n",
    "$$\n",
    "2p = 1 + \\text{erf}(x \\sqrt{\\pi})$$ \n",
    "$$\n",
    "\\text{erf}(x \\sqrt{\\pi}) = 2p - 1$$ \n",
    "$$\n",
    "x \\sqrt{\\pi} = \\text{erf}^{-1}(2p - 1)$$ \n",
    "$$\n",
    "x = \\frac{\\text{erf}^{-1}(2p - 1)}{\\sqrt{\\pi}}$$ \n",
    "\n",
    "Therefore, the quantile function Q(p) is:\n",
    "$$\n",
    "Q(p) = \\frac{\\text{erf}^{-1}(2p - 1)}{\\sqrt{\\pi}}$$  \n",
    "\n",
    "Therefore the CDF and Qunatile function is given as follows: \n",
    "$$ \n",
    "F(x) = \\frac{1}{2} \\left(1 + \\text{erf}(x \\sqrt{\\pi})\\right)\n",
    "$$  \n",
    "\n",
    "\n",
    "$$\n",
    "Q(p) = \\frac{\\text{erf}^{-1}(2p - 1)}{\\sqrt{\\pi}}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSamplingHelper <- function(n){ \n",
    " p <- runif(n)\n",
    "  \n",
    "  # empty vector to store the generated numbers\n",
    "  numbers <- numeric(n)\n",
    "  \n",
    "  #  erf function \n",
    "  erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1\n",
    "  \n",
    "  # Defining approximate inverse erf function\n",
    "  erfinv <- function(y) qnorm((y + 1) / 2) / sqrt(2)\n",
    "  \n",
    "  # quantile function Q(p)\n",
    "  Q <- function(p) {\n",
    "    return(erfinv(2 * p - 1) / sqrt(pi))\n",
    "  }\n",
    "  \n",
    "  # random numbers generation using the quantile function Q(p)\n",
    "  for (i in 1:n) {\n",
    "    numbers[i] <- Q(p[i])\n",
    "  }\n",
    "  \n",
    "  # array of generated numbers\n",
    "  return(numbers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAA/wBNTU1oaGh8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\nJAABEAlAAEQCEOA/gV8m9y0wZ94AAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Sampled Numbers with Theoretical Density\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123) # eproducibility\n",
    "sampled_numbers <- newSamplingHelper(99999)\n",
    "\n",
    "# Histogram plot with 100 bins\n",
    "hist(sampled_numbers, breaks=100, probability=TRUE, \n",
    "     main=\"Sampled Numbers with Theoretical Density\",\n",
    "     xlab=\"x\", col=\"lightblue\", border=\"black\")\n",
    "\n",
    "# theoretical density function f(x)\n",
    "f <- function(x) {\n",
    "  exp(-x^2 * pi)\n",
    "}\n",
    "\n",
    "# x values sequence for plotting the theoretical density\n",
    "x_vals <- seq(min(sampled_numbers), max(sampled_numbers), length.out=1000)\n",
    "y_vals <- f(x_vals)\n",
    "\n",
    "# theoretical density curve\n",
    "lines(x_vals, y_vals, col=\"green\", lwd=2)\n",
    "\n",
    "# legend\n",
    "legend(\"topright\", legend=c(\"Theoretical Density\"), col=\"green\", lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: (g) \n",
    "The histogram of the sampled numbers resembles the theoretical density function $f(x) = e^{-x^2\\pi}$\n",
    "above, which is a Gaussian-like curve. The curve is similar to that of a standard Gaussian distribution with a peak at\n",
    "x=0 and a tail that diminish symmetrically on both sides. The distribution generated using equation\n",
    "above, however, has the factor of $\\pi$, which influences the speed at which the tails diminish. The higher the value of $\\pi$, the steeper the distribution with less thick tails, and the lower the value, the flatter the distribution with fatter tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FIT5197_A2_Final_Draft_Edited_by_Dan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
